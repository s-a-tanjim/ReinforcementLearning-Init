{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faf2bfb-ba7e-40d0-9f2a-4aab75216b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 11:14:08.406154: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "915174ce-d1d8-4577-999e-ed304cec2ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of State Space ->  3\n",
      "Size of Action Space ->  1\n",
      "Max Value of Action ->  2.0\n",
      "Min Value of Action ->  -2.0\n"
     ]
    }
   ],
   "source": [
    "# env = gym.make(\"CarRacing-v0\")\n",
    "env = gym.make(\"Pendulum-v1\")\n",
    "\n",
    "num_states = env.observation_space.shape[0]\n",
    "print(\"Size of State Space ->  {}\".format(num_states))\n",
    "num_actions = env.action_space.shape[0]\n",
    "print(\"Size of Action Space ->  {}\".format(num_actions))\n",
    "\n",
    "upper_bound = env.action_space.high[0]\n",
    "lower_bound = env.action_space.low[0]\n",
    "\n",
    "print(\"Max Value of Action ->  {}\".format(upper_bound))\n",
    "print(\"Min Value of Action ->  {}\".format(lower_bound))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "436ab67b-3314-4e72-a8c9-72eb7f35fe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUActionNoise:\n",
    "    def __init__(self, mean, std_deviation, theta=0.15, dt=1e-2, x_initial=None):\n",
    "        self.theta = theta\n",
    "        self.mean = mean\n",
    "        self.std_dev = std_deviation\n",
    "        self.dt = dt\n",
    "        self.x_initial = x_initial\n",
    "        self.reset()\n",
    "\n",
    "    def __call__(self):\n",
    "        # Formula taken from https://www.wikipedia.org/wiki/Ornstein-Uhlenbeck_process.\n",
    "        x = (\n",
    "            self.x_prev\n",
    "            + self.theta * (self.mean - self.x_prev) * self.dt\n",
    "            + self.std_dev * np.sqrt(self.dt) * np.random.normal(size=self.mean.shape)\n",
    "        )\n",
    "        # Store x into x_prev\n",
    "        # Makes next noise dependent on current one\n",
    "        self.x_prev = x\n",
    "        return x\n",
    "\n",
    "    def reset(self):\n",
    "        if self.x_initial is not None:\n",
    "            self.x_prev = self.x_initial\n",
    "        else:\n",
    "            self.x_prev = np.zeros_like(self.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41f7c610-4a1e-4417-905d-31644d90cb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer:\n",
    "    def __init__(self, buffer_capacity=100000, batch_size=64):\n",
    "        # Number of \"experiences\" to store at max\n",
    "        self.buffer_capacity = buffer_capacity\n",
    "        # Num of tuples to train on.\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Its tells us num of times record() was called.\n",
    "        self.buffer_counter = 0\n",
    "\n",
    "        # Instead of list of tuples as the exp.replay concept go\n",
    "        # We use different np.arrays for each tuple element\n",
    "        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        self.action_buffer = np.zeros((self.buffer_capacity, num_actions))\n",
    "        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "\n",
    "    # Takes (s,a,r,s') obervation tuple as input\n",
    "    def record(self, obs_tuple):\n",
    "        # Set index to zero if buffer_capacity is exceeded,\n",
    "        # replacing old records\n",
    "        index = self.buffer_counter % self.buffer_capacity\n",
    "\n",
    "        self.state_buffer[index] = obs_tuple[0]\n",
    "        self.action_buffer[index] = obs_tuple[1]\n",
    "        self.reward_buffer[index] = obs_tuple[2]\n",
    "        self.next_state_buffer[index] = obs_tuple[3]\n",
    "\n",
    "        self.buffer_counter += 1\n",
    "\n",
    "    # Eager execution is turned on by default in TensorFlow 2. Decorating with tf.function allows\n",
    "    # TensorFlow to build a static graph out of the logic and computations in our function.\n",
    "    # This provides a large speed up for blocks of code that contain many small TensorFlow operations such as this one.\n",
    "    @tf.function\n",
    "    def update(\n",
    "        self, state_batch, action_batch, reward_batch, next_state_batch,\n",
    "    ):\n",
    "        # Training and updating Actor & Critic networks.\n",
    "        # See Pseudo Code.\n",
    "        with tf.GradientTape() as tape:\n",
    "            target_actions = target_actor(next_state_batch, training=True)\n",
    "            y = reward_batch + gamma * target_critic(\n",
    "                [next_state_batch, target_actions], training=True\n",
    "            )\n",
    "            critic_value = critic_model([state_batch, action_batch], training=True)\n",
    "            critic_loss = tf.math.reduce_mean(tf.math.square(y - critic_value))\n",
    "\n",
    "        critic_grad = tape.gradient(critic_loss, critic_model.trainable_variables)\n",
    "        critic_optimizer.apply_gradients(\n",
    "            zip(critic_grad, critic_model.trainable_variables)\n",
    "        )\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            actions = actor_model(state_batch, training=True)\n",
    "            critic_value = critic_model([state_batch, actions], training=True)\n",
    "            # Used `-value` as we want to maximize the value given\n",
    "            # by the critic for our actions\n",
    "            actor_loss = -tf.math.reduce_mean(critic_value)\n",
    "\n",
    "        actor_grad = tape.gradient(actor_loss, actor_model.trainable_variables)\n",
    "        actor_optimizer.apply_gradients(\n",
    "            zip(actor_grad, actor_model.trainable_variables)\n",
    "        )\n",
    "\n",
    "    # We compute the loss and update parameters\n",
    "    def learn(self):\n",
    "        # Get sampling range\n",
    "        record_range = min(self.buffer_counter, self.buffer_capacity)\n",
    "        # Randomly sample indices\n",
    "        batch_indices = np.random.choice(record_range, self.batch_size)\n",
    "\n",
    "        # Convert to tensors\n",
    "        state_batch = tf.convert_to_tensor(self.state_buffer[batch_indices])\n",
    "        action_batch = tf.convert_to_tensor(self.action_buffer[batch_indices])\n",
    "        reward_batch = tf.convert_to_tensor(self.reward_buffer[batch_indices])\n",
    "        reward_batch = tf.cast(reward_batch, dtype=tf.float32)\n",
    "        next_state_batch = tf.convert_to_tensor(self.next_state_buffer[batch_indices])\n",
    "\n",
    "        self.update(state_batch, action_batch, reward_batch, next_state_batch)\n",
    "\n",
    "\n",
    "# This update target parameters slowly\n",
    "# Based on rate `tau`, which is much less than one.\n",
    "@tf.function\n",
    "def update_target(target_weights, weights, tau):\n",
    "    for (a, b) in zip(target_weights, weights):\n",
    "        a.assign(b * tau + a * (1 - tau))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de8c14a4-15f6-4395-b469-79ccef1a06a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor():\n",
    "    # Initialize weights between -3e-3 and 3-e3\n",
    "    last_init = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)\n",
    "\n",
    "    inputs = layers.Input(shape=(num_states,))\n",
    "    out = layers.Dense(256, activation=\"relu\")(inputs)\n",
    "    out = layers.Dense(256, activation=\"relu\")(out)\n",
    "    outputs = layers.Dense(1, activation=\"tanh\", kernel_initializer=last_init)(out)\n",
    "\n",
    "    # Our upper bound is 2.0 for Pendulum.\n",
    "    outputs = outputs * upper_bound\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_critic():\n",
    "    # State as input\n",
    "    state_input = layers.Input(shape=(num_states))\n",
    "    state_out = layers.Dense(16, activation=\"relu\")(state_input)\n",
    "    state_out = layers.Dense(32, activation=\"relu\")(state_out)\n",
    "\n",
    "    # Action as input\n",
    "    action_input = layers.Input(shape=(num_actions))\n",
    "    action_out = layers.Dense(32, activation=\"relu\")(action_input)\n",
    "\n",
    "    # Both are passed through seperate layer before concatenating\n",
    "    concat = layers.Concatenate()([state_out, action_out])\n",
    "\n",
    "    out = layers.Dense(256, activation=\"relu\")(concat)\n",
    "    out = layers.Dense(256, activation=\"relu\")(out)\n",
    "    outputs = layers.Dense(1)(out)\n",
    "\n",
    "    # Outputs single value for give state-action\n",
    "    model = tf.keras.Model([state_input, action_input], outputs)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bad32475-7fa7-4e57-a1b2-18e0904bc7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(state, noise_object):\n",
    "    sampled_actions = tf.squeeze(actor_model(state))\n",
    "    noise = noise_object()\n",
    "    # Adding noise to action\n",
    "    sampled_actions = sampled_actions.numpy() + noise\n",
    "\n",
    "    # We make sure action is within bounds\n",
    "    legal_action = np.clip(sampled_actions, lower_bound, upper_bound)\n",
    "\n",
    "    return [np.squeeze(legal_action)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "149fd46a-17fd-4494-940a-0c98266b612f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-15 16:39:56.795983: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "std_dev = 0.2\n",
    "ou_noise = OUActionNoise(mean=np.zeros(1), std_deviation=float(std_dev) * np.ones(1))\n",
    "\n",
    "actor_model = get_actor()\n",
    "critic_model = get_critic()\n",
    "\n",
    "target_actor = get_actor()\n",
    "target_critic = get_critic()\n",
    "\n",
    "# Making the weights equal initially\n",
    "target_actor.set_weights(actor_model.get_weights())\n",
    "target_critic.set_weights(critic_model.get_weights())\n",
    "\n",
    "# Learning rate for actor-critic models\n",
    "critic_lr = 0.002\n",
    "actor_lr = 0.001\n",
    "\n",
    "critic_optimizer = tf.keras.optimizers.Adam(critic_lr)\n",
    "actor_optimizer = tf.keras.optimizers.Adam(actor_lr)\n",
    "\n",
    "total_episodes = 100\n",
    "# Discount factor for future rewards\n",
    "gamma = 0.99\n",
    "# Used to update target networks\n",
    "tau = 0.005\n",
    "\n",
    "buffer = Buffer(50000, 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af9fe45e-a3b8-484d-8019-357a3938a189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode * 0 * Avg Reward is ==> -1550.911252439204\n",
      "Episode * 1 * Avg Reward is ==> -1725.2248771792429\n",
      "Episode * 2 * Avg Reward is ==> -1623.1892096168367\n",
      "Episode * 3 * Avg Reward is ==> -1593.7151515870632\n",
      "Episode * 4 * Avg Reward is ==> -1590.2492777030714\n",
      "Episode * 5 * Avg Reward is ==> -1607.8058320702548\n",
      "Episode * 6 * Avg Reward is ==> -1592.387769971903\n",
      "Episode * 7 * Avg Reward is ==> -1579.86228321724\n",
      "Episode * 8 * Avg Reward is ==> -1516.5572956023293\n",
      "Episode * 9 * Avg Reward is ==> -1516.950444523844\n",
      "Episode * 10 * Avg Reward is ==> -1521.643341574812\n",
      "Episode * 11 * Avg Reward is ==> -1497.5949296952258\n",
      "Episode * 12 * Avg Reward is ==> -1464.9777649403086\n",
      "Episode * 13 * Avg Reward is ==> -1449.7832781316613\n",
      "Episode * 14 * Avg Reward is ==> -1433.7841974758803\n",
      "Episode * 15 * Avg Reward is ==> -1418.619604688127\n",
      "Episode * 16 * Avg Reward is ==> -1356.579803721139\n",
      "Episode * 17 * Avg Reward is ==> -1364.200502886618\n",
      "Episode * 18 * Avg Reward is ==> -1312.8660501823995\n",
      "Episode * 19 * Avg Reward is ==> -1278.3167593172607\n",
      "Episode * 20 * Avg Reward is ==> -1229.376445284188\n",
      "Episode * 21 * Avg Reward is ==> -1201.6813592323108\n",
      "Episode * 22 * Avg Reward is ==> -1166.0254127007952\n",
      "Episode * 23 * Avg Reward is ==> -1122.5213557825348\n",
      "Episode * 24 * Avg Reward is ==> -1082.7759187961765\n",
      "Episode * 25 * Avg Reward is ==> -1045.9430236104822\n",
      "Episode * 26 * Avg Reward is ==> -1016.2163731027999\n",
      "Episode * 27 * Avg Reward is ==> -984.424019964852\n",
      "Episode * 28 * Avg Reward is ==> -954.9158100518475\n",
      "Episode * 29 * Avg Reward is ==> -923.1448654810964\n",
      "Episode * 30 * Avg Reward is ==> -903.7550111324479\n",
      "Episode * 31 * Avg Reward is ==> -883.4244789529922\n",
      "Episode * 32 * Avg Reward is ==> -864.0149954114778\n",
      "Episode * 33 * Avg Reward is ==> -842.0428124038224\n",
      "Episode * 34 * Avg Reward is ==> -821.4688450925837\n",
      "Episode * 35 * Avg Reward is ==> -802.0395562673082\n",
      "Episode * 36 * Avg Reward is ==> -783.6907021505367\n",
      "Episode * 37 * Avg Reward is ==> -766.3571690069892\n",
      "Episode * 38 * Avg Reward is ==> -752.5654783883441\n",
      "Episode * 39 * Avg Reward is ==> -736.7736043247606\n",
      "Episode * 40 * Avg Reward is ==> -698.0425258103467\n",
      "Episode * 41 * Avg Reward is ==> -653.7049585184924\n",
      "Episode * 42 * Avg Reward is ==> -621.2257753782555\n",
      "Episode * 43 * Avg Reward is ==> -586.5758968383166\n",
      "Episode * 44 * Avg Reward is ==> -547.1860152507982\n",
      "Episode * 45 * Avg Reward is ==> -507.70297023089535\n",
      "Episode * 46 * Avg Reward is ==> -473.0700809167829\n",
      "Episode * 47 * Avg Reward is ==> -441.53147280403493\n",
      "Episode * 48 * Avg Reward is ==> -422.225559773072\n",
      "Episode * 49 * Avg Reward is ==> -390.3735232000606\n",
      "Episode * 50 * Avg Reward is ==> -351.188804778926\n",
      "Episode * 51 * Avg Reward is ==> -333.4824520749022\n",
      "Episode * 52 * Avg Reward is ==> -319.3714353241829\n",
      "Episode * 53 * Avg Reward is ==> -290.93244412563\n",
      "Episode * 54 * Avg Reward is ==> -280.15002482852594\n",
      "Episode * 55 * Avg Reward is ==> -272.36202668054494\n",
      "Episode * 56 * Avg Reward is ==> -269.07349417322473\n",
      "Episode * 57 * Avg Reward is ==> -234.92032044154035\n",
      "Episode * 58 * Avg Reward is ==> -228.2095031957991\n",
      "Episode * 59 * Avg Reward is ==> -215.77567783879567\n",
      "Episode * 60 * Avg Reward is ==> -212.47037393049413\n",
      "Episode * 61 * Avg Reward is ==> -199.87766048963846\n",
      "Episode * 62 * Avg Reward is ==> -193.19041717350774\n",
      "Episode * 63 * Avg Reward is ==> -190.1734770130208\n",
      "Episode * 64 * Avg Reward is ==> -192.86377043075296\n",
      "Episode * 65 * Avg Reward is ==> -195.6456019950746\n",
      "Episode * 66 * Avg Reward is ==> -192.50222069800648\n",
      "Episode * 67 * Avg Reward is ==> -189.3835304680102\n",
      "Episode * 68 * Avg Reward is ==> -189.27701865789362\n",
      "Episode * 69 * Avg Reward is ==> -192.19940608197467\n",
      "Episode * 70 * Avg Reward is ==> -190.0701924465092\n",
      "Episode * 71 * Avg Reward is ==> -189.6077885312049\n",
      "Episode * 72 * Avg Reward is ==> -183.61004657978964\n",
      "Episode * 73 * Avg Reward is ==> -180.72468056620056\n",
      "Episode * 74 * Avg Reward is ==> -180.8129985419872\n",
      "Episode * 75 * Avg Reward is ==> -186.21390650094477\n",
      "Episode * 76 * Avg Reward is ==> -192.57825814144115\n",
      "Episode * 77 * Avg Reward is ==> -198.55773628158403\n",
      "Episode * 78 * Avg Reward is ==> -199.06852741880587\n",
      "Episode * 79 * Avg Reward is ==> -199.23323500223034\n",
      "Episode * 80 * Avg Reward is ==> -202.3825016216231\n",
      "Episode * 81 * Avg Reward is ==> -205.43542135766583\n",
      "Episode * 82 * Avg Reward is ==> -211.3785808561156\n",
      "Episode * 83 * Avg Reward is ==> -211.39967055899234\n",
      "Episode * 84 * Avg Reward is ==> -214.50359550753214\n",
      "Episode * 85 * Avg Reward is ==> -214.54541800419784\n",
      "Episode * 86 * Avg Reward is ==> -214.82013491417175\n",
      "Episode * 87 * Avg Reward is ==> -212.19705491008818\n",
      "Episode * 88 * Avg Reward is ==> -209.19740143153732\n",
      "Episode * 89 * Avg Reward is ==> -209.29378654136107\n",
      "Episode * 90 * Avg Reward is ==> -215.3686895132405\n",
      "Episode * 91 * Avg Reward is ==> -205.27946276296092\n",
      "Episode * 92 * Avg Reward is ==> -198.2137553969687\n",
      "Episode * 93 * Avg Reward is ==> -198.45179261287942\n",
      "Episode * 94 * Avg Reward is ==> -182.1999213101056\n",
      "Episode * 95 * Avg Reward is ==> -169.12249367222626\n",
      "Episode * 96 * Avg Reward is ==> -166.26973336948268\n",
      "Episode * 97 * Avg Reward is ==> -169.09216433138369\n",
      "Episode * 98 * Avg Reward is ==> -169.0042310348144\n",
      "Episode * 99 * Avg Reward is ==> -174.08306845322613\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To store reward history of each episode\n",
    "ep_reward_list = []\n",
    "# To store average reward history of last few episodes\n",
    "avg_reward_list = []\n",
    "\n",
    "# Takes about 4 min to train\n",
    "for ep in range(total_episodes):\n",
    "\n",
    "    prev_state = env.reset()\n",
    "    episodic_reward = 0\n",
    "\n",
    "    while True:\n",
    "        # Uncomment this to see the Actor in action\n",
    "        # But not in a python notebook.\n",
    "        # env.render()\n",
    "\n",
    "        tf_prev_state = tf.expand_dims(tf.convert_to_tensor(prev_state), 0)\n",
    "\n",
    "        action = policy(tf_prev_state, ou_noise)\n",
    "        # Recieve state and reward from environment.\n",
    "        state, reward, done, info = env.step(action)\n",
    "\n",
    "        buffer.record((prev_state, action, reward, state))\n",
    "        episodic_reward += reward\n",
    "\n",
    "        buffer.learn()\n",
    "        update_target(target_actor.variables, actor_model.variables, tau)\n",
    "        update_target(target_critic.variables, critic_model.variables, tau)\n",
    "\n",
    "        # End this episode when `done` is True\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        prev_state = state\n",
    "\n",
    "    ep_reward_list.append(episodic_reward)\n",
    "\n",
    "    # Mean of last 40 episodes\n",
    "    avg_reward = np.mean(ep_reward_list[-40:])\n",
    "    print(\"Episode * {} * Avg Reward is ==> {}\".format(ep, avg_reward))\n",
    "    avg_reward_list.append(avg_reward)\n",
    "\n",
    "# Plotting graph\n",
    "# Episodes versus Avg. Rewards\n",
    "plt.plot(avg_reward_list)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Avg. Epsiodic Reward\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
